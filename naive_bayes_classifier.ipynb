{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF - Term frequency - Inverse Document Frequency, i.e. tf-idf = tf * idf ##\n",
    "TF-IDF enables us to gives us a way to associate each word in a document with a number that represents how relevant each word is in that document.\n",
    "`\n",
    "t is the term/ word\n",
    "d is the document\n",
    "D is the total number of documents\n",
    "{ d ∈ D : t ∈ d } denotes the number of documents in which t occur\n",
    "\n",
    "tf-idf = tf * idf\n",
    "\n",
    "Term Frequency = count(t, d) i.e count of term t in document d\n",
    "Normalized term frequency = count(t,d)/Total terms in that document.\n",
    "Logarithmic Term Frequency = 1 + log10(count(t,d))\n",
    "idf ( t, d ) = log ( D / { d ∈ D : t ∈ d })\n",
    "`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "import pandas as pd #pandas to deal with tabular data\n",
    "import numpy as np #numpy for number crunching\n",
    "from sklearn import metrics #sklearn provides different ml models & methods to prepare training and test data\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from csv files\n",
    "# Dataset used ImDb Movie Reviews Dataset https://www.kaggle.com/mantri7/imdb-movie-reviews-dataset?select=train_data+%281%29.csv\n",
    "# Data shape \n",
    "# ['user-review', 'label(0-bad, 1-good)']\n",
    "train_data_from_csv = pd.read_csv('train_data.csv')\n",
    "test_data_from_csv = pd.read_csv('test_data.csv')\n",
    "\n",
    "      \n",
    "X_train = train_data_from_csv['0']\n",
    "y_train = train_data_from_csv['1']\n",
    "X_test = test_data_from_csv['0']\n",
    "y_test = test_data_from_csv['1']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# usinf countVectorizer\n",
    "tf_vectorizer = CountVectorizer()\n",
    "# extract all the unique words and transform is to make term frequency matrix\n",
    "# we can fit and then trasform but using fit_transform we can do both the steps in single statement\n",
    "# fit is to extract all the unique words i.e vocabulary\n",
    "# transform is to make term frequency matrix of the data for all the unique terms extracted from fit part\n",
    "X_train_tf = tf_vectorizer.fit_transform(X_train)\n",
    "# transform the test data into TF vectorized matrix note dont do fit on X_test again because we dont want do create a new vocabulary instead use\n",
    "# the same vocabulary we extracted from training data\n",
    "X_test_tf = tf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build naive bayes classification model\n",
    "nbclf = MultinomialNB()\n",
    "# train model \n",
    "nbclf.fit(X_train_tf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "accuracy:   0.814\n",
      "------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Bad       0.78      0.88      0.82     12500\n",
      "        Good       0.86      0.75      0.80     12500\n",
      "\n",
      "    accuracy                           0.81     25000\n",
      "   macro avg       0.82      0.81      0.81     25000\n",
      "weighted avg       0.82      0.81      0.81     25000\n",
      "\n",
      "------------------------------\n",
      "[0]\n"
     ]
    }
   ],
   "source": [
    "# predict the output from testing data(unseen data)\n",
    "y_pred = nbclf.predict(X_test_tf)\n",
    "# find the accuracy of the model\n",
    "score = metrics.accuracy_score(y_test, y_pred)\n",
    "print('------------------------------')\n",
    "print(\"accuracy:   %0.3f\" % score)\n",
    "print('------------------------------')\n",
    "print(metrics.classification_report(y_test, y_pred, target_names=['Bad', 'Good']))\n",
    "print('------------------------------')\n",
    "print(nbclf.predict(tf_vectorizer.transform([\"bad\"])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tfidf_vectorizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-7e902ab27954>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# load model from file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmodel_loded_from_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'nbclf.joblib'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_loded_from_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtfidf_vectorizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"good\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'tfidf_vectorizer' is not defined"
     ]
    }
   ],
   "source": [
    "# save model to file\n",
    "joblib.dump(nbclf, 'nbclf.joblib')\n",
    "# load model from file\n",
    "model_loded_from_file = joblib.load('nbclf.joblib')\n",
    "print(model_loded_from_file.predict(tf_vectorizer.transform([\"good\"])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
