{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF - Term frequency - Inverse Document Frequency, i.e. tf-idf = tf * idf ##\n",
    "TF-IDF enables us to gives us a way to associate each word in a document with a number that represents how relevant each word is in that document.\n",
    "`\n",
    "t is the term/ word\n",
    "d is the document\n",
    "D is the total number of documents\n",
    "{ d ∈ D : t ∈ d } denotes the number of documents in which t occur\n",
    "\n",
    "tf-idf = tf * idf\n",
    "\n",
    "Term Frequency = count(t, d) i.e count of term t in document d\n",
    "Normalized term frequency = count(t,d)/Total terms in that document.\n",
    "Logarithmic Term Frequency = 1 + log10(count(t,d))\n",
    "idf ( t, d ) = log ( D / { d ∈ D : t ∈ d })\n",
    "`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "import pandas as pd #pandas to deal with tabular data\n",
    "import numpy as np #numpy for number crunching\n",
    "from sklearn import metrics #sklearn provides different ml models & methods to prepare training and test data\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from csv files\n",
    "# Dataset used ImDb Movie Reviews Dataset https://www.kaggle.com/mantri7/imdb-movie-reviews-dataset?select=train_data+%281%29.csv\n",
    "# Data shape \n",
    "# ['user-review', 'label(0-bad, 1-good)']\n",
    "train_data_from_csv = pd.read_csv('train_data.csv')\n",
    "test_data_from_csv = pd.read_csv('test_data.csv')\n",
    "\n",
    "      \n",
    "X_train = train_data_from_csv['0']\n",
    "y_train = train_data_from_csv['1']\n",
    "X_test = test_data_from_csv['0']\n",
    "y_test = test_data_from_csv['1']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting words as features from the training and testing sets and making corresponding feature matrices\n",
    "tfidf_vectorizer = TfidfVectorizer(analyzer=\"word\", stop_words=\"english\", max_features=1200)\n",
    "# extract all the unique words and transform is to make term frequency matrix\n",
    "# we can fit and then trasform but using fit_transform we can do both the steps in single statement\n",
    "# fit is to extract all the unique words i.e vocabulary\n",
    "# transform is to make term frequency matrix of the data for all the unique terms extracted from fit part\n",
    "X_train_tf = tfidf_vectorizer.fit_transform(X_train)\n",
    "# transform the test data into TF vectorized matrix note dont do fit on X_test again because we dont want do create a new vocabulary instead use\n",
    "# the same vocabulary we extracted from training data\n",
    "X_test_tf = tfidf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build naive bayes classification model\n",
    "nbclf = MultinomialNB()\n",
    "# train model \n",
    "nbclf.fit(X_train_tf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "accuracy:   0.835\n",
      "------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Bad       0.84      0.83      0.83     12500\n",
      "        Good       0.83      0.84      0.84     12500\n",
      "\n",
      "    accuracy                           0.84     25000\n",
      "   macro avg       0.84      0.84      0.84     25000\n",
      "weighted avg       0.84      0.84      0.84     25000\n",
      "\n",
      "------------------------------\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "# predict the output from testing data(unseen data)\n",
    "y_pred = nbclf.predict(X_test_tf)\n",
    "# find the accuracy of the model\n",
    "score = metrics.accuracy_score(y_test, y_pred)\n",
    "print('------------------------------')\n",
    "print(\"accuracy:   %0.3f\" % score)\n",
    "print('------------------------------')\n",
    "print(metrics.classification_report(y_test, y_pred, target_names=['Bad', 'Good']))\n",
    "print('------------------------------')\n",
    "print(nbclf.predict(tfidf_vectorizer.transform([\"good\"])))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
